{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95603bf-4661-4fb3-9225-4973957195ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import utils,math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import mss\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    # เพิ่มจำนวน detect หน้าสูงสุด\n",
    "    max_num_faces=2,\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "count = 0\n",
    "seconds = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.VideoCapture('video/source/2/CB_SOS_11042022.mp4')\n",
    "\n",
    "ith_sample = 0\n",
    "status = list('-'*20)\n",
    "\n",
    "# variables \n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "\n",
    "# *-------------------------------*\n",
    "#screen size\n",
    "monitor = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 500}\n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]\n",
    "#data list csv\n",
    "countF = 0\n",
    "countL = 0\n",
    "countR = 0\n",
    "countU = 0\n",
    "countD = 0\n",
    "X_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8cf9fa-55f2-44a7-ac9b-ab967c69a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "header = ['forward','left', 'right', 'up', 'down',]\n",
    "data_train = [\n",
    "    [countF, countL,  countR, countU,  countD],\n",
    "]\n",
    "def build_CSV():\n",
    "    with open('data_train_test.csv', 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        # Use writerows() not writerow()\n",
    "        writer.writerows(data_train)\n",
    "def landmarksDetection(img, landmark, draw=False):\n",
    "        img_height, img_width= img.shape[:2]\n",
    "        # list[(x,y), (x,y)....]\n",
    "        mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in landmark]\n",
    "        if draw :\n",
    "            [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "\n",
    "        # returning the list of tuples for each landmarks \n",
    "        return mesh_coord\n",
    "\n",
    "# Euclaidean distance \n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance\n",
    "\n",
    "# Blinking Ratio\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "\n",
    "    reRatio = rhDistance/rvDistance\n",
    "    leRatio = lhDistance/lvDistance\n",
    "\n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio \n",
    "\n",
    "\n",
    "# Eyes Extrctor function,\n",
    "build_CSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecbd0c-59af-4f10-9679-fe9a5a58c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mss.darwin.MSS object at 0x7fb5231a29d0>\n"
     ]
    }
   ],
   "source": [
    "# landmark detection function \n",
    "with mss.mss() as sct:\n",
    "    success = True\n",
    "    print(mss.mss())\n",
    "    while \"Screen capturing\":\n",
    "        image = np.array(sct.grab(monitor))\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ith_sample += 1\n",
    "        start = time.time()\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # Also convert the color space from BGR to RGB\n",
    "        # image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Get the result\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Convert the color space from RGB to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        img_h, img_w, img_c = image.shape\n",
    "        face_3d = []\n",
    "        face_2d = []\n",
    "\n",
    "        # จำนวนคน\n",
    "        # print('len(results.multi_face_landmarks)')\n",
    "        # print(len(results.multi_face_landmarks))\n",
    "\n",
    "        cv2.putText(image, str(ith_sample), (20, 500), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "        #cv2.putText(image, ' '.join(status), (20, 550), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            \n",
    "            currentDate = str(datetime.datetime.now())\n",
    "            for i,face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "\n",
    "                # เพิ่มกรอบหน้าขาว\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=drawing_spec,\n",
    "                    connection_drawing_spec=drawing_spec)\n",
    "\n",
    "                # ส่วนของการกระพริบตา\n",
    "                mesh_coords = landmarksDetection(image, face_landmarks.landmark, False)\n",
    "                try:\n",
    "                    ratio = blinkRatio(image, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "                except:\n",
    "                    print(\"An exception occurred\")\n",
    "                # cv2.putText(image, f'Ratio : {round(ratio,2)}', (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                if ratio >3.5: # ตรวจการกระพริบของตา\n",
    "                    CEF_COUNTER +=1\n",
    "                    # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                    utils.colorBackgroundText(image,  f'Blink', cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20, 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "\n",
    "                else:\n",
    "                    if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                        TOTAL_BLINKS +=1\n",
    "                        CEF_COUNTER =0\n",
    "\n",
    "                # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "                # utils.colorBackgroundText(image,  f'Total Blinks: {TOTAL_BLINKS}', cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20,150),2)\n",
    "                cv2.polylines(image,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.RED, 1, cv2.LINE_AA) # map ตาซ้าย\n",
    "                cv2.polylines(image,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv2.LINE_AA) # map ตาขวา\n",
    "                face_2d = []\n",
    "                face_3d = []\n",
    "                for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                    # เอาไว้หาตำแหน่งจุดของหน้า\n",
    "                    # test_x, test_y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                    # cv2.circle(image, (test_x, test_y), 2, (255, 0, 0), -1)\n",
    "                    # cv2.putText(image, str(idx), (test_x, test_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "                    # เก็บตำแหน่งบนหน้าผาก\n",
    "                    if idx == 10:\n",
    "                        header_x,header_y = int(lm.x * img_w), (int(lm.y * img_h))\n",
    "                        color_nose = (255, 0, 0)\n",
    "                    # เก็บตำแหน่งจมูก\n",
    "                    if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                        # print('mosss',i)\n",
    "                        if idx == 1:\n",
    "                            nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                            nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "                        x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                        # Get the 2D Coordinates\n",
    "                        face_2d.append([x, y])\n",
    "\n",
    "                        # Get the 3D Coordinates\n",
    "                        face_3d.append([x, y, lm.z])\n",
    "\n",
    "                # Convert it to the NumPy array\n",
    "                face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "                # Convert it to the NumPy array\n",
    "                face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                # The camera matrix\n",
    "                focal_length = 1 * img_w\n",
    "\n",
    "                cam_matrix = np.array([[focal_length, 0, img_h / 2],\n",
    "                                       [0, focal_length, img_w / 2],\n",
    "                                       [0, 0, 1]])\n",
    "\n",
    "                # The distortion parameters\n",
    "                dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "                # Solve PnP\n",
    "                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "                # Get rotational matrix\n",
    "                rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "                # Get angles\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "                # Get the y rotation degree\n",
    "                x = angles[0] * 360\n",
    "                y = angles[1] * 360\n",
    "                z = angles[2] * 360\n",
    "\n",
    "                start_point = (5, 220)\n",
    "                end_point = (440, 440)\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "\n",
    "\n",
    "                countF = 0\n",
    "                countL = 0\n",
    "                countR = 0\n",
    "                countU = 0\n",
    "                countD = 0\n",
    "                # See where the user's head tilting\n",
    "                if y < -5:\n",
    "                    text = \"Looking Right\"\n",
    "                    str_status = \"R\"\n",
    "                    count = count+1\n",
    "                    countR = 1\n",
    "                    cv2.rectangle(image,(0,0),(image.shape[1],image.shape[0]),(0,0,255),10)\n",
    "                    color_nose = (0, 0, 255)\n",
    "                elif y > 5:\n",
    "                    text = \"Looking Left\"\n",
    "                    str_status = \"L\"\n",
    "                    count = count+1\n",
    "                    countL = 1\n",
    "                    cv2.rectangle(image,(0,0),(image.shape[1],image.shape[0]),(0,0,255),10)\n",
    "                    color_nose = (0, 0, 255)\n",
    "                elif x < -5:\n",
    "                    text = \"Looking Down\"\n",
    "                    str_status = \"D\"\n",
    "                    countD = 1\n",
    "                    cv2.rectangle(image,(0,0),(image.shape[1],image.shape[0]),(0,0,255),10)\n",
    "                    color_nose = (0, 0, 255)\n",
    "                elif x > 5:\n",
    "                    text = \"Looking Up\"\n",
    "                    str_status = \"U\"\n",
    "                    countU = 1\n",
    "                    cv2.rectangle(image,(0,0),(image.shape[1],image.shape[0]),(0,255,0),10)\n",
    "                    color_nose = (255, 0, 0)\n",
    "                else:\n",
    "                    text = \"Forward\"\n",
    "                    count = count-1\n",
    "                    countF = 1\n",
    "                    str_status = \"-\"\n",
    "                    cv2.rectangle(image,(0,0),(image.shape[1],image.shape[0]),(0,255,0),10)\n",
    "                    color_nose = (255, 0, 0)\n",
    "                data_train.append([countF, countL,  countR, countU,  countD])\n",
    "\n",
    "\n",
    "                # genXtest()\n",
    "                # print(data_train)\n",
    "                # update status\n",
    "                if ith_sample % 10 == 0:\n",
    "                    status.append(str_status)\n",
    "                    status.pop(0)\n",
    "                # Display the nose direction\n",
    "                nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "                p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "                p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "                cv2.line(image, p1, p2, color_nose, 3)\n",
    "                # Add the text on the image\n",
    "                cv2.putText(image, text, (header_x,header_y), cv2.FONT_HERSHEY_SIMPLEX, 1, color_nose, 2)\n",
    "                # cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "                # cv2.putText(image, \"x: \" + str(np.round(x, 2)), (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                # cv2.putText(image, \"y: \" + str(np.round(y, 2)), (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                # cv2.putText(image, \"z: \" + str(np.round(z, 2)), (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "            end = time.time()\n",
    "            totalTime = end - start\n",
    "\n",
    "            fps = 1 / totalTime\n",
    "\n",
    "            #cv2.putText(image, f'FPS: {int(fps)}', (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Head Pose Estimation1', image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    # cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
