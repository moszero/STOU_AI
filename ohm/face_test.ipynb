{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83183525-d19d-4172-8174-40c82f92d9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import utils,math\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    # เพิ่มจำนวน detect หน้าสูงสุด\n",
    "    max_num_faces=1,\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "count = 0\n",
    "seconds = time.time()\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture('video/IMG_0378.mp4')\n",
    "\n",
    "ith_sample = 0\n",
    "status = list('-'*20)\n",
    "\n",
    "# variables \n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "\n",
    "# *-------------------------------*\n",
    "\n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]\n",
    "\n",
    "# landmark detection function \n",
    "def landmarksDetection(img, landmark, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    # list[(x,y), (x,y)....]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in landmark]\n",
    "    if draw :\n",
    "        [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "\n",
    "    # returning the list of tuples for each landmarks \n",
    "    return mesh_coord\n",
    "\n",
    "# Euclaidean distance \n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance\n",
    "\n",
    "# Blinking Ratio\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "\n",
    "    reRatio = rhDistance/rvDistance\n",
    "    leRatio = lhDistance/lvDistance\n",
    "\n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio \n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    ith_sample += 1\n",
    "    start = time.time()\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Also convert the color space from BGR to RGB\n",
    "    # image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Get the result\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Convert the color space from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "\n",
    "    # จำนวนคน\n",
    "    # print('len(results.multi_face_landmarks)')\n",
    "    # print(len(results.multi_face_landmarks))\n",
    "    \n",
    "    cv2.putText(image, str(ith_sample), (20, 500), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "    cv2.putText(image, ' '.join(status), (20, 550), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        currentDate = str(datetime.datetime.now())\n",
    "        for i,face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "            \n",
    "            # เพิ่มกรอบหน้าขาว\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec)\n",
    "            \n",
    "            # ส่วนของการกระพริบตา\n",
    "            mesh_coords = landmarksDetection(image, face_landmarks.landmark, False)\n",
    "            ratio = blinkRatio(image, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "            cv2.putText(image, f'Ratio : {round(ratio,2)}', (20, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            if ratio >4.5:\n",
    "                CEF_COUNTER +=1\n",
    "                # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                utils.colorBackgroundText(image,  f'Blink', cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20, 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "\n",
    "            else:\n",
    "                if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                    TOTAL_BLINKS +=1\n",
    "                    CEF_COUNTER =0\n",
    "            # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "            utils.colorBackgroundText(image,  f'Total Blinks: {TOTAL_BLINKS}', cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20,150),2)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            face_2d = []\n",
    "            face_3d = []\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                # เอาไว้หาตำแหน่งจุดของหน้า\n",
    "                # test_x, test_y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                # cv2.circle(image, (test_x, test_y), 2, (255, 0, 0), -1)\n",
    "                # cv2.putText(image, str(idx), (test_x, test_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                \n",
    "                # เก็บตำแหน่งบนหน้าผาก\n",
    "                if idx == 10:\n",
    "                    header_x,header_y = int(lm.x * img_w), (int(lm.y * img_h))\n",
    "                    \n",
    "                # เก็บตำแหน่งจมูก\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    # print('mosss',i)\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    # Get the 2D Coordinates\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    # Get the 3D Coordinates\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "            # Convert it to the NumPy array\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "            # Convert it to the NumPy array\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            # The camera matrix\n",
    "            focal_length = 1 * img_w\n",
    "\n",
    "            cam_matrix = np.array([[focal_length, 0, img_h / 2],\n",
    "                                   [0, focal_length, img_w / 2],\n",
    "                                   [0, 0, 1]])\n",
    "\n",
    "            # The distortion parameters\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            # Solve PnP\n",
    "            success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            # Get rotational matrix\n",
    "            rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "            # Get angles\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            # Get the y rotation degree\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "            z = angles[2] * 360\n",
    "            \n",
    "            start_point = (5, 220)\n",
    "            end_point = (440, 440)\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            # See where the user's head tilting\n",
    "            if y < -5:\n",
    "                text = \"Looking Right\"\n",
    "                str_status = \"R\"\n",
    "                count = count+1\n",
    "            elif y > 5:\n",
    "                text = \"Looking Left\"\n",
    "                str_status = \"L\"\n",
    "                count = count+1\n",
    "            elif x < -7:\n",
    "                text = \"Looking Down\"\n",
    "                str_status = \"D\"\n",
    "            elif x > 8:\n",
    "                text = \"Looking Up\"\n",
    "                str_status = \"U\"\n",
    "            else:\n",
    "                text = \"Forward\"\n",
    "                count = count-1\n",
    "                str_status = \"-\"\n",
    "                \n",
    "            # update status\n",
    "            if ith_sample % 10 == 0:\n",
    "                status.append(str_status)\n",
    "                status.pop(0)\n",
    "            \n",
    "            # ตรวจจับการเข้าข่ายการโกง \n",
    "            if count > 70:\n",
    "                test = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "            if count <= 0:\n",
    "                count = 0\n",
    "                \n",
    "            # Display the nose direction\n",
    "            nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "            p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "            \n",
    "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "            # Add the text on the image\n",
    "            \n",
    "            cv2.putText(image, text, (header_x,header_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            # cv2.putText(image, \"x: \" + str(np.round(x, 2)), (header_x,header_y-100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image, \"y: \" + str(np.round(y, 2)), (header_x,header_y-80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image, \"z: \" + str(np.round(z, 2)), (header_x,header_y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image,currentDate,(header_x,header_y-40),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),cv2.LINE_4)\n",
    "            cv2.putText(image, \"count: \" + str(np.round(count, 2)), (header_x,header_y-25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "            # cv2.putText(image, \"x: \" + str(np.round(x, 2)), (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image, \"y: \" + str(np.round(y, 2)), (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image, \"z: \" + str(np.round(z, 2)), (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            # cv2.putText(image,currentDate,(500,200),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),cv2.LINE_4)\n",
    "            # cv2.putText(image, \"count: \" + str(np.round(count, 2)), (500, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "\n",
    "        fps = 1 / totalTime\n",
    "\n",
    "        cv2.putText(image, f'FPS: {int(fps)}', (20, 450), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1de9c9-ab76-4bf7-a7e9-772685dfbb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to /Users/paperlessmac2/opt/anaconda3/lib/python3.9/site-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca0718-3867-4c00-b7fd-aeb64734171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Also convert the color space from BGR to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Get the result\n",
    "    results = face_mesh.process(image)\n",
    "    \n",
    "    # To improve performance\n",
    "    image.flags.writeable = True\n",
    "    \n",
    "    # Convert the color space from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    # Get the 2D Coordinates\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    # Get the 3D Coordinates\n",
    "                    face_3d.append([x, y, lm.z])       \n",
    "            \n",
    "            # Convert it to the NumPy array\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "            # Convert it to the NumPy array\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            # The camera matrix\n",
    "            focal_length = 1 * img_w\n",
    "\n",
    "            cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                    [0, focal_length, img_w / 2],\n",
    "                                    [0, 0, 1]])\n",
    "\n",
    "            # The distortion parameters\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            # Solve PnP\n",
    "            success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            # Get rotational matrix\n",
    "            rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "            # Get angles\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            # Get the y rotation degree\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "            z = angles[2] * 360\n",
    "          \n",
    "\n",
    "            # See where the user's head tilting\n",
    "            if y < -10:\n",
    "                text = \"Looking Left\"\n",
    "            elif y > 10:\n",
    "                text = \"Looking Right\"\n",
    "            elif x < -10:\n",
    "                text = \"Looking Down\"\n",
    "            elif x > 10:\n",
    "                text = \"Looking Up\"\n",
    "            else:\n",
    "                text = \"Forward\"\n",
    "            \n",
    "            # print(x)\n",
    "            # Display the nose direction\n",
    "            nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "            p2 = (int(nose_2d[0] + y * 10) , int(nose_2d[1] - x * 10))\n",
    "            \n",
    "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "            # Add the text on the image\n",
    "            cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "            cv2.putText(image, \"x: \" + str(np.round(x,2)), (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"y: \" + str(np.round(y,2)), (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"z: \" + str(np.round(z,2)), (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "\n",
    "        fps = 1 / totalTime\n",
    "        #print(\"FPS: \", fps)\n",
    "\n",
    "        cv2.putText(image, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    # connections=mp_face_mesh.FACE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=drawing_spec,\n",
    "                    connection_drawing_spec=drawing_spec)\n",
    "\n",
    "\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
